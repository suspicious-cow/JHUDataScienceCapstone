---
title: "Johns Hopkins University Data Science Capstone - Milestone Report"
author: "Zain Naboulsi"
date: "2023-05-13"
bibliography: references.bib
output:
  html_document:
    
    toc: yes
  pdf_document:
    
    toc: yes
editor_options: 
  markdown: 
    
    wrap: 80
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE, appendix = TRUE}


```

# Introduction
Welcome to Zain Naboulsi's Milestone Report for the Johns Hopkins Data Science Specialization. I apprecate you taking time to review my work and give feedback on progress as well as thoughts on fitting a prediction model. Also, any insight you would like to share on the final plan for my Shiny application would be welcome. 

I started by taking three very large text files that were taken from blogs, news, and Twitter entries on the Internet. Initially I had planned to do analysis on the entire set of data; however that idea quickly dissolved as my first attempt generating counts of each word took over sixteen hours to complete. Naturally, this was a non-starter. 

I then turned my full attention to the total size of the original source files. 

```{r, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE, appendix = TRUE}





```

# Inital Data Load
In this portion of the project, we are undertaking the first step of our analysis: loading the data. We begin by specifying the location of our data, which resides in text files within the 'SwiftKeyData' folder. To facilitate subsequent analysis, we utilize the 'readtext' function to import the data from these text files into our working environment. The data at this point exists as a collection of separate text documents. To make the data easier to work with and analyze collectively, we then transform this collection of documents into a 'corpus'. In the realm of text analysis, a 'corpus' refers to a structured set of texts, which serves as our comprehensive data set for the subsequent stages of our investigation. Finally, we create a document-feature matrix to get an idea of the word frequency that exists. 

```{r, echo = FALSE, warning = FALSE, error = FALSE, message = FALSE, appendix = TRUE, cache = TRUE}


```

\newpage
# References  

<div id="refs"></div>  


# Appendix: All Source Code  

```{r ref.label = knitr::all_labels(appendix == TRUE), echo=TRUE, eval=FALSE}
```